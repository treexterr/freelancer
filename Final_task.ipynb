{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img src=\"../images/sberbank.png\">\n",
    "# <center> Финальное задание </center>\n",
    "## <center> Предсказание пола клиента по транзакциям</center>\n",
    "\n",
    "## Описание задачи \n",
    "### В рамках финального задания будет необходимо предсказывать пол клиента, основываясь на его транзакционных исторических данных. Выполнение финального задания - это маленький шаг в большую Data Science-всесенную, поэтому отнеситесь к нему максимально серьёзно :)\n",
    "### Вы будете строить предиктивные модели и отправлять результаты своего моделирования на платформу [Kaggle](https://www.kaggle.com/t/e8a939488d274dab9051cce14d5ca952), где и будет оцениваться каждое решение и положение участников. Но переживать не стоит - код, связанный с построением модели мы уже написали, поэтому вашим основным заданием будет создание новых переменных для генерации новых инсайдов из данных, которые смогут улучшить полученные значения метрики.\n",
    "### В роли метрики выступает [ROC AUC](https://dyakonov.org/2017/07/28/auc-roc-%D0%BF%D0%BB%D0%BE%D1%89%D0%B0%D0%B4%D1%8C-%D0%BF%D0%BE%D0%B4-%D0%BA%D1%80%D0%B8%D0%B2%D0%BE%D0%B9-%D0%BE%D1%88%D0%B8%D0%B1%D0%BE%D0%BA/), который и нужно будет оптимизировать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T17:34:52.054851Z",
     "start_time": "2019-03-05T17:34:51.515762Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "from warnings import filterwarnings\n",
    "\n",
    "%matplotlib inline\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T17:34:58.314241Z",
     "start_time": "2019-03-05T17:34:52.056205Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Считываем данные\n",
    "tr_mcc_codes = pd.read_csv('../data/tr_mcc_codes.csv', sep=';', index_col='mcc_code')\n",
    "tr_types = pd.read_csv('../data/tr_types.csv', sep=';', index_col='tr_type')\n",
    "\n",
    "transactions = pd.read_csv('../data/transactions.csv', index_col='customer_id')\n",
    "gender_train = pd.read_csv('../data/gender_train.csv', index_col='customer_id')\n",
    "gender_test = pd.read_csv('../data/gender_test.csv', index_col='customer_id')\n",
    "transactions_train = transactions.join(gender_train, how='inner')\n",
    "transactions_test = transactions.join(gender_test, how='inner')\n",
    "\n",
    "del transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T17:34:58.354996Z",
     "start_time": "2019-03-05T17:34:58.315591Z"
    }
   },
   "outputs": [],
   "source": [
    "# Функции, которыми можно пользоваться для построения классификатора, \n",
    "# оценки его результатов и построение прогноза для тестовой части пользователей\n",
    "\n",
    "# Cross-validation score (среднее значение метрики ROC AUC на тренировочных данных)\n",
    "def cv_score(params, train, y_true):\n",
    "    cv_res=xgb.cv(params, xgb.DMatrix(train, y_true),\n",
    "                  early_stopping_rounds=10, maximize=True, \n",
    "                  num_boost_round=10000, nfold=5, stratified=True)\n",
    "    index_argmax = cv_res['test-auc-mean'].argmax()\n",
    "    print('Cross-validation, ROC AUC: {:.3f}+-{:.3f}, Trees: {}'.format(cv_res.loc[index_argmax]['test-auc-mean'],\n",
    "                                                                        cv_res.loc[index_argmax]['test-auc-std'],\n",
    "                                                                        index_argmax))\n",
    "\n",
    "# Построение модели + возврат результатов классификации тестовых пользователей\n",
    "def fit_predict(params, num_trees, train, test, target):\n",
    "    params['learning_rate'] = params['eta']\n",
    "    clf = xgb.train(params, xgb.DMatrix(train.values, target, feature_names=list(train.columns)), \n",
    "                    num_boost_round=num_trees, maximize=True)\n",
    "    y_pred = clf.predict(xgb.DMatrix(test.values, feature_names=list(train.columns)))\n",
    "    submission = pd.DataFrame(index=test.index, data=y_pred, columns=['probability'])\n",
    "    return clf, submission\n",
    "\n",
    "# Отрисовка важности переменных. Важность переменной - количество разбиений выборки, \n",
    "# в которых участвует данная переменная. Чем больше - тем она, вероятно, лучше \n",
    "def draw_feature_importances(clf, top_k=10):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    \n",
    "    importances = dict(sorted(clf.get_score().items(), key=lambda x: x[1])[-top_k:])\n",
    "    y_pos = np.arange(len(importances))\n",
    "    \n",
    "    plt.barh(y_pos, list(importances.values()), align='center', color='green')\n",
    "    plt.yticks(y_pos, importances.keys(), fontsize=12)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.xlabel('Feature importance', fontsize=15)\n",
    "    plt.title('Features importances, Sberbank Gender Prediction', fontsize=18)\n",
    "    plt.ylim(-0.5, len(importances) - 0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Так как код для оценки модели на тренировочных данных и её применения на тестовых данных уже дан, то мы будем работать над тем, чтобы создать переменные для улучшения результатов моделирования. \n",
    "\n",
    "### (!) В рамках данного задания Вы можете делать всё, что угодно - использовать другие алгоритмы и/или их комбинации, подбирать гиперпараметры своих моделей, отбирать переменые, etc. Мы создали шаблон для простоты и для Вашего понимания верхнеуровневого процесса разработки модели, опустив при этом большое число деталей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic features\n",
    "Начнём с того, что сформируем базовые переменные по каждому пользователю. На этом этапе будем использовать стандартные агрегации, посчитанные на расходах и приходах клиента:\n",
    "- минимум\n",
    "- максимум\n",
    "- среднее\n",
    "- медиана\n",
    "- среднеквадратичное отклонение\n",
    "- количество\n",
    "\n",
    "Также параметры модели выберем стандартные, запишем их в словарь params, и будем использовать для дальнейшего построения модели (не забывайте, что с этим Вы можете тоже экспериментировать)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T17:34:58.362104Z",
     "start_time": "2019-03-05T17:34:58.356308Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'eta': 0.1,\n",
    "    'max_depth': 3,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    \n",
    "    'gamma': 0,\n",
    "    'lambda': 0,\n",
    "    'alpha': 0,\n",
    "    'min_child_weight': 0,\n",
    "    \n",
    "    'eval_metric': 'auc',\n",
    "    'objective': 'binary:logistic' ,\n",
    "    'booster': 'gbtree',\n",
    "    'njobs': -1,\n",
    "    'tree_method': 'approx'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T17:35:41.272300Z",
     "start_time": "2019-03-05T17:34:58.363622Z"
    }
   },
   "outputs": [],
   "source": [
    "tqdm_notebook.pandas(desc=\"Progress:\")\n",
    "\n",
    "def features_creation_basic(x): \n",
    "    features = []\n",
    "    features.append(pd.Series(x[x['amount']>0]['amount'].agg(['min', 'max', 'mean', 'median', 'std', 'count'])\\\n",
    "                                                        .add_prefix('positive_transactions_')))\n",
    "    features.append(pd.Series(x[x['amount']<0]['amount'].agg(['min', 'max', 'mean', 'median', 'std', 'count'])\\\n",
    "                                                        .add_prefix('negative_transactions_')))\n",
    " \n",
    "    return pd.concat(features)\n",
    "\n",
    "data_train = transactions_train.groupby(transactions_train.index).progress_apply(features_creation_basic)\n",
    "data_test = transactions_test.groupby(transactions_test.index).progress_apply(features_creation_basic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T17:35:45.011046Z",
     "start_time": "2019-03-05T17:35:41.273326Z"
    }
   },
   "outputs": [],
   "source": [
    "target = data_train.join(gender_train, how='inner')['gender']\n",
    "cv_score(params, data_train, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T17:35:45.714620Z",
     "start_time": "2019-03-05T17:35:45.018570Z"
    }
   },
   "outputs": [],
   "source": [
    "### Число деревьев для XGBoost имеет смысл выставлять по результатам на кросс-валидации \n",
    "clf, submission = fit_predict(params, 70, data_train, data_test, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T17:35:45.897370Z",
     "start_time": "2019-03-05T17:35:45.719320Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "draw_feature_importances(clf, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('../data/basic_features_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Видим, что результат на кросс-валидации - 62.5% ROC AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced features\n",
    "Добавим дополнительные переменные по каждому пользователю в модель. <br>\n",
    "Для этого будем анализировать дни недели, часы и состояние дня/ночи во время покупки - в каждом из случаев будем считать частоту транзакций в соответствующей категории относитеьно всех остальных категорий. <br>\n",
    "То есть если, например, клиент в 70% случае совершал ночные траты, то мы получим вектор [0.7, 0.3] для этого случая в качестве частот транзакций ночью/днём."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T17:35:57.677748Z",
     "start_time": "2019-03-05T17:35:45.921444Z"
    }
   },
   "outputs": [],
   "source": [
    "for df in [transactions_train, transactions_test]:\n",
    "    df['day'] = df['tr_datetime'].str.split().apply(lambda x: int(x[0]) % 7)\n",
    "    df['hour'] = df['tr_datetime'].apply(lambda x: re.search(' \\d*', x).group(0)).astype(int)\n",
    "    df['night'] = ~df['hour'].between(6, 22).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T17:35:57.687397Z",
     "start_time": "2019-03-05T17:35:57.678823Z"
    }
   },
   "outputs": [],
   "source": [
    "def features_creation_advanced(x): \n",
    "    features = []\n",
    "    features.append(pd.Series(x['day'].value_counts(normalize=True).add_prefix('day_')))\n",
    "    features.append(pd.Series(x['hour'].value_counts(normalize=True).add_prefix('hour_')))\n",
    "    features.append(pd.Series(x['night'].value_counts(normalize=True).add_prefix('night_')))\n",
    "    features.append(pd.Series(x[x['amount']>0]['amount'].agg(['min', 'max', 'mean', 'median', 'std', 'count'])\\\n",
    "                                                        .add_prefix('positive_transactions_')))\n",
    "    features.append(pd.Series(x[x['amount']<0]['amount'].agg(['min', 'max', 'mean', 'median', 'std', 'count'])\\\n",
    "                                                        .add_prefix('negative_transactions_')))\n",
    " \n",
    "    return pd.concat(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T17:37:19.784321Z",
     "start_time": "2019-03-05T17:35:57.688448Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train = transactions_train.groupby(transactions_train.index)\\\n",
    "                               .progress_apply(features_creation_advanced).unstack(-1)\n",
    "data_test = transactions_test.groupby(transactions_test.index)\\\n",
    "                             .progress_apply(features_creation_advanced).unstack(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T17:37:27.200528Z",
     "start_time": "2019-03-05T17:37:19.785535Z"
    }
   },
   "outputs": [],
   "source": [
    "target = data_train.join(gender_train, how='inner')['gender']\n",
    "cv_score(params, data_train, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T17:37:28.307548Z",
     "start_time": "2019-03-05T17:37:27.205214Z"
    }
   },
   "outputs": [],
   "source": [
    "### Число деревьев для XGBoost имеет смысл выятавлять по результатам на кросс-валидации \n",
    "clf, submission = fit_predict(params, 70, data_train, data_test, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T17:37:28.426836Z",
     "start_time": "2019-03-05T17:37:28.308620Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "draw_feature_importances(clf, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Добавление новых переменных улучшило наши результаты ROC AUC с 62.5% до 68.2%, на тестовой выборке результат будет аналогичным, так что мы явно не переобучились. При этом есть куда стремиться!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### В итоге можем отправить полученное решение на платформу в Kaggle In-Class Competition. Для этого выгрузим его в *.csv - файл, после чего полученный файл можем загружать в качестве ответа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T17:37:28.448839Z",
     "start_time": "2019-03-05T17:37:28.438234Z"
    }
   },
   "outputs": [],
   "source": [
    "submission.to_csv('../data/submission_advanced.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (!) Цель задания:\n",
    "## Полученная модель должна иметь ROC AUC на Public-части тестовой выборки (на лидерборде) не менее 80%."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
